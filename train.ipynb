{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from datasets.kitti_raw_monosf import KITTI_Raw_KittiSplit_Train, KITTI_Raw_KittiSplit_Valid\n",
    "from models.CNet import CNet\n",
    "from augmentations import Augmentation_SceneFlow\n",
    "\n",
    "# args\n",
    "args = {\n",
    "    'batch_size' : 1,\n",
    "    'num_workers' : 2,\n",
    "    'epochs': 1, \n",
    "    'lr': 2e-4,\n",
    "    'momentum': 0.9,\n",
    "    'beta': 0.999,\n",
    "    'weight_decay': 0.0,\n",
    "    'train': True,\n",
    "    'cuda': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/external/datasets/kitti_data_jpg/'\n",
    "train_dataset = KITTI_Raw_KittiSplit_Train(args={}, root=data_root)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args['batch_size'], num_workers=args['num_workers'], shuffle=True, pin_memory=True)\n",
    "# val_dataset = KITTI_Raw_KittiSplit_Valid(args={}, root=data_root)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=args['batch_size'], num_workers=args['num_workers'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 256\n"
     ]
    }
   ],
   "source": [
    "%autoreload \n",
    "\n",
    "augmentation = Augmentation_SceneFlow(args)\n",
    "model = CNet(args)\n",
    "\n",
    "if args['cuda']:\n",
    "    augmentation = augmentation.cuda()\n",
    "    model = model.cuda()\n",
    "\n",
    "params = model.parameters()\n",
    "\n",
    "optimizer = Adam(params, lr=args['lr'], betas=[args['momentum'], args['beta']], weight_decay=args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 7.92620849609375 Gb\n",
      "free     : 6.02313232421875 Gb\n",
      "used     : 1.903076171875 Gb\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "import pynvml\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total / (1024**3)} Gb')\n",
    "print(f'free     : {info.free / (1024**3)} Gb')\n",
    "print(f'used     : {info.used / (1024**3)} Gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agumentation\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "DEBUG correlation: torch.Size([1, 256, 4, 13]) torch.Size([1, 256, 4, 13])\n",
      "[81, 256, 64, 3, 3, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "DEBUG correlation: torch.Size([1, 192, 8, 26]) torch.Size([1, 192, 8, 26])\n",
      "DEBUG l>1: torch.Size([1, 81, 8, 26]) torch.Size([1, 192, 8, 26]) torch.Size([1, 32, 4, 13]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 8, 26])\n",
      "[81, 192, 64, 3, 3, 1, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "DEBUG correlation: torch.Size([1, 128, 16, 52]) torch.Size([1, 128, 16, 52])\n",
      "DEBUG l>1: torch.Size([1, 81, 16, 52]) torch.Size([1, 128, 16, 52]) torch.Size([1, 32, 8, 26]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 16, 52])\n",
      "[81, 128, 64, 3, 3, 1, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "DEBUG correlation: torch.Size([1, 96, 32, 104]) torch.Size([1, 96, 32, 104])\n",
      "DEBUG l>1: torch.Size([1, 81, 32, 104]) torch.Size([1, 96, 32, 104]) torch.Size([1, 32, 16, 52]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 32, 104])\n",
      "[81, 96, 64, 3, 3, 1, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "DEBUG correlation: torch.Size([1, 64, 64, 208]) torch.Size([1, 64, 64, 208])\n",
      "DEBUG l>1: torch.Size([1, 81, 64, 208]) torch.Size([1, 64, 64, 208]) torch.Size([1, 32, 32, 104]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 64, 208])\n",
      "[81, 64, 64, 3, 3, 1, 1, 1]\n",
      "DEBUG correlation: torch.Size([1, 256, 4, 13]) torch.Size([1, 256, 4, 13])\n",
      "[81, 256, 64, 3, 3, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "DEBUG correlation: torch.Size([1, 192, 8, 26]) torch.Size([1, 192, 8, 26])\n",
      "DEBUG l>1: torch.Size([1, 81, 8, 26]) torch.Size([1, 192, 8, 26]) torch.Size([1, 32, 4, 13]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 8, 26])\n",
      "[81, 192, 64, 3, 3, 1, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.77191162109375 Gb\n",
      "used     : 5.154296875 Gb\n",
      "DEBUG correlation: torch.Size([1, 128, 16, 52]) torch.Size([1, 128, 16, 52])\n",
      "DEBUG l>1: torch.Size([1, 81, 16, 52]) torch.Size([1, 128, 16, 52]) torch.Size([1, 32, 8, 26]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 16, 52])\n",
      "[81, 128, 64, 3, 3, 1, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.75042724609375 Gb\n",
      "used     : 5.17578125 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.75042724609375 Gb\n",
      "used     : 5.17578125 Gb\n",
      "DEBUG correlation: torch.Size([1, 96, 32, 104]) torch.Size([1, 96, 32, 104])\n",
      "DEBUG l>1: torch.Size([1, 81, 32, 104]) torch.Size([1, 96, 32, 104]) torch.Size([1, 32, 16, 52]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 32, 104])\n",
      "[81, 96, 64, 3, 3, 1, 1, 1]\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.73870849609375 Gb\n",
      "used     : 5.1875 Gb\n",
      "sceneflow util\n",
      "total    : 7.92620849609375 Gb\n",
      "free     : 2.73870849609375 Gb\n",
      "used     : 5.1875 Gb\n",
      "DEBUG correlation: torch.Size([1, 64, 64, 208]) torch.Size([1, 64, 64, 208])\n",
      "DEBUG l>1: torch.Size([1, 81, 64, 208]) torch.Size([1, 64, 64, 208]) torch.Size([1, 32, 32, 104]) torch.Size([1, 3, 4, 13]) torch.Size([1, 1, 64, 208])\n",
      "[81, 64, 64, 3, 3, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "for data_dict in train_loader:\n",
    "    # Get input and target tensor keys\n",
    "    input_keys = list(filter(lambda x: \"input\" in x, data_dict.keys()))\n",
    "    target_keys = list(filter(lambda x: \"target\" in x, data_dict.keys()))\n",
    "    tensor_keys = input_keys + target_keys\n",
    "\n",
    "    # Possibly transfer to Cuda\n",
    "    if args['cuda']:\n",
    "        for key, value in data_dict.items():\n",
    "            if key in tensor_keys:\n",
    "                data_dict[key] = value.cuda(non_blocking=True)\n",
    "            \n",
    "    if augmentation is not None:\n",
    "        with torch.no_grad():\n",
    "            data_dict = augmentation(data_dict)\n",
    "        \n",
    "    x = model(data_dict)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x\n",
    "del data_dict\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentations import Augmentation_ScaleCrop\n",
    "\n",
    "a = Augmentation_ScaleCrop(None)\n",
    "a.calculate_tform_and_grids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, augmentations):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for i, data in enumerate(dataloader):\n",
    "    continue\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f3535e70fcd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(args['epochs']):\n",
    "    loss_one_epoch = train_one_epoch(model, dataloader, optimizer, augmentations=augmentation)\n",
    "    optimizer.zero_grad()\n",
    "    loss_one_epoch.backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dim_corr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ebf3483bd9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mnum_ch_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim_corr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mnum_ch_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim_corr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dim_corr' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, dilation=1, isReLU=True):\n",
    "    if isReLU:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, dilation=dilation,\n",
    "                      padding=((kernel_size - 1) * dilation) // 2, bias=True),\n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, dilation=dilation,\n",
    "                      padding=((kernel_size - 1) * dilation) // 2, bias=True)\n",
    "        )\n",
    "    \n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, num_chs):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.num_chs = num_chs\n",
    "        self.convs = nn.ModuleList()\n",
    "\n",
    "        for _, (ch_in, ch_out) in enumerate(zip(num_chs[:-1], num_chs[1:])):\n",
    "            layer = nn.Sequential(\n",
    "                conv(ch_in, ch_out, stride=2),\n",
    "                conv(ch_out, ch_out)\n",
    "            )\n",
    "            self.convs.append(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_pyramid = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "            feature_pyramid.append(x)\n",
    "\n",
    "        return feature_pyramid[::-1]\n",
    "\n",
    "class MaskNetDecoder(nn.Module):\n",
    "  def __init__(self, in_ch, num_refs=1):\n",
    "    super(MaskNetDecoder, self).__init__()\n",
    "\n",
    "    conv_chs = [256, 256, 128, 64, 32, 16]\n",
    "    self.convs = nn.Sequential(\n",
    "      conv(in_ch,       in_ch,       kernel_size=7),\n",
    "      conv(in_ch,       conv_chs[0], kernel_size=5),\n",
    "      conv(conv_chs[0], conv_chs[1]),\n",
    "      conv(conv_chs[1], conv_chs[2]),\n",
    "      conv(conv_chs[2], conv_chs[3]),\n",
    "      conv(conv_chs[3], conv_chs[4]),\n",
    "      conv(conv_chs[4], conv_chs[5]),\n",
    "    )\n",
    "\n",
    "    self.pred_mask = conv(conv_chs[-1], num_refs)\n",
    "    self.pred_mask_upconv = upconv_transpose(num_refs, num_refs)\n",
    "    self.refine_upconv = conv(num_refs, num_refs)\n",
    "    \n",
    "  def forward(self, pyr_feat, nlevel):\n",
    "    out_conv = self.convs(pyr_feat)\n",
    "    mask = self.pred_mask(out_conv)\n",
    "    pred_mask = nn.functional.sigmoid(mask)\n",
    "    mask_upconv = self.pred_mask_upconv(mask)\n",
    "    pred_mask_upconv = nn.functional.sigmoid(self.refine_upconv(mask_upconv))\n",
    "\n",
    "    return pred_mask, pred_mask_upconv  # (B, num_refs, H, W), (B, num_refs, H*2, W*2)    \n",
    "\n",
    "\n",
    "convs = nn.ModuleList()\n",
    "mask_decoders = nn.ModuleList()\n",
    "\n",
    "num_chs = [3, 32, 64, 96, 128, 192, 256]\n",
    "search_range = 4\n",
    "output_level = 4\n",
    "num_levels   = 7\n",
    "\n",
    "for l, ch in enumerate(num_chs[::-1]):\n",
    "    if l > output_level:\n",
    "                break\n",
    "    if l == 0:\n",
    "        num_ch_in = dim_corr + ch \n",
    "    else:\n",
    "        num_ch_in = dim_corr + ch + 32 + 3 + 1\n",
    "    print(num_ch_in)\n",
    "    \n",
    "x = torch.rand(256, 832, 3).permute(2, 0, 1).unsqueeze(0)\n",
    "feat_extractor = FeatureExtractor(num_chs)\n",
    "pyr = feat_extractor(x)\n",
    "print([_.shape for _ in pyr] + [x.shape])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SF",
   "language": "python",
   "name": "sf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
